# -*- coding: utf-8 -*-
"""lab3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DYpyZisJS9dfwLi1F0bRUKidNWzZMYPJ

Лабораторная работа №3. Классификация изображений CNN. Байрамов Руслан 23-ИИ. Вариант 1 (Xception)
"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_recall_curve, PrecisionRecallDisplay
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import label_binarize
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.applications import Xception
from tensorflow.keras.applications.xception import preprocess_input, decode_predictions
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
import tensorflow_datasets as tfds
from itertools import cycle
import warnings
warnings.filterwarnings('ignore')

print("Библиотеки загружены успешно")

"""Загрузка предобученной сети Xception"""

print("\n=== Загрузка предобученной сети Xception ===")
model_xception = Xception(weights='imagenet', include_top=True)
print("Модель Xception загружена успешно")
print(f"Входной размер: {model_xception.input_shape}")
print(f"Выходной размер: {model_xception.output_shape}")

"""Классификация изображения из интернета"""

print("\n=== Классификация изображения ===")

def classify_image_from_url(url):
    """Классификация изображения по URL"""
    try:
        # Скачивание изображения через requests
        import requests
        from io import BytesIO
        from PIL import Image

        response = requests.get(url, timeout=10)
        response.raise_for_status()

        # Загрузка и подготовка изображения
        image = Image.open(BytesIO(response.content))
        image = image.convert('RGB')  # Убеждаемся, что изображение в RGB
        image = image.resize((299, 299))  # Xception требует 299x299

        image_array = img_to_array(image)
        image_array = np.expand_dims(image_array, axis=0)
        image_array = preprocess_input(image_array)

        # Предсказание
        predictions = model_xception.predict(image_array)
        decoded_predictions = decode_predictions(predictions, top=3)[0]

        # Отображение результатов
        plt.figure(figsize=(12, 5))

        plt.subplot(1, 2, 1)
        plt.imshow(image)
        plt.axis('off')
        plt.title('Исходное изображение')

        plt.subplot(1, 2, 2)
        classes = [pred[1] for pred in decoded_predictions]
        probabilities = [pred[2] for pred in decoded_predictions]

        bars = plt.barh(classes, probabilities)
        plt.xlabel('Вероятность')
        plt.title('Топ-3 предсказания')

        # Добавляем значения на столбцы
        for bar, prob in zip(bars, probabilities):
            plt.text(bar.get_width() - 0.05, bar.get_y() + bar.get_height()/2,
                    f'{prob:.4f}', ha='right', va='center', color='white', fontweight='bold')

        plt.tight_layout()
        plt.show()

        print("Топ-3 предсказания:")
        for i, (imagenet_id, label, score) in enumerate(decoded_predictions):
            print(f"{i+1}. {label}: {score:.4f}")

        return decoded_predictions

    except Exception as e:
        print(f"Ошибка при обработке изображения: {e}")
        return None

# Используем работающие URL с изображениями
image_urls = [
    "https://images.unsplash.com/photo-1546182990-dffeafbe841d?w=400",  # лошадь
    "https://images.unsplash.com/photo-1514888286974-6c03e2ca1dba?w=400",  # кошка
    "https://images.unsplash.com/photo-1561037404-61cd46aa615b?w=400"  # собака
]

print("Классификация изображения лошади:")
success = False
for i, url in enumerate(image_urls):
    print(f"Попытка {i+1}")
    predictions = classify_image_from_url(url)
    if predictions:
        success = True
        print("Классификация выполнена успешно!")
        break

if not success:
    print("\nИспользуем встроенные тестовые изображения Keras...")
    # Используем встроенные тестовые изображения из Keras
    from tensorflow.keras.datasets import cifar10
    import cv2

    # Загружаем CIFAR-10 и берем случайное изображение
    (x_train, y_train), (x_test, y_test) = cifar10.load_data()

    # Берем случайное изображение и увеличиваем его до 299x299
    random_idx = np.random.randint(0, len(x_train))
    test_image = x_train[random_idx]
    test_image = cv2.resize(test_image, (299, 299))

    # Подготавливаем изображение
    image_array = np.expand_dims(test_image, axis=0)
    image_array = preprocess_input(image_array)

    # Предсказание
    predictions = model_xception.predict(image_array)
    decoded_predictions = decode_predictions(predictions, top=3)[0]

    # Отображение результатов
    plt.figure(figsize=(12, 5))

    plt.subplot(1, 2, 1)
    plt.imshow(test_image)
    plt.axis('off')
    plt.title('Тестовое изображение (CIFAR-10)')

    plt.subplot(1, 2, 2)
    classes = [pred[1] for pred in decoded_predictions]
    probabilities = [pred[2] for pred in decoded_predictions]

    bars = plt.barh(classes, probabilities)
    plt.xlabel('Вероятность')
    plt.title('Топ-3 предсказания')

    for bar, prob in zip(bars, probabilities):
        plt.text(bar.get_width() - 0.05, bar.get_y() + bar.get_height()/2,
                f'{prob:.4f}', ha='right', va='center', color='white', fontweight='bold')

    plt.tight_layout()
    plt.show()

    print("Топ-3 предсказания для тестового изображения:")
    for i, (imagenet_id, label, score) in enumerate(decoded_predictions):
        print(f"{i+1}. {label}: {score:.4f}")

"""Загрузка и анализ наборов данных"""

print("\n=== Загрузка наборов данных ===")

def load_and_analyze_dataset(dataset_name, split=None):
    """Загрузка и анализ набора данных"""
    print(f"\n--- Анализ набора данных: {dataset_name} ---")

    try:
        # Для cats_vs_dogs используем только train и затем разделим вручную
        if dataset_name == 'cats_vs_dogs':
            # Загрузка только train split
            dataset, info = tfds.load(
                dataset_name,
                split='train',
                with_info=True,
                as_supervised=True,
                shuffle_files=True
            )

            # Определяем общее количество примеров
            dataset_size = info.splits['train'].num_examples
            train_size = int(0.8 * dataset_size)

            # Разделяем вручную на train/test
            train_ds = dataset.take(train_size)
            test_ds = dataset.skip(train_size)

            return (train_ds, test_ds), info

        else:
            # Для других датасетов используем стандартное разделение
            (train_ds, test_ds), info = tfds.load(
                dataset_name,
                split=['train', 'test'],
                with_info=True,
                as_supervised=True,
                shuffle_files=True
            )
            return (train_ds, test_ds), info

    except Exception as e:
        print(f"Ошибка при загрузке {dataset_name}: {e}")
        # Альтернативный способ загрузки
        print("Используем альтернативный метод загрузки...")
        dataset, info = tfds.load(
            dataset_name,
            split='train',
            with_info=True,
            as_supervised=True
        )

        # Разделяем вручную
        dataset_size = sum(1 for _ in dataset)
        train_size = int(0.8 * dataset_size)

        train_ds = dataset.take(train_size)
        test_ds = dataset.skip(train_size)

        return (train_ds, test_ds), info

def count_labels(dataset):
    """Подсчет меток в dataset"""
    labels = []
    for _, label in dataset:
        labels.append(label.numpy())
    return np.bincount(labels)

# Загрузка horses_or_humans
print("Загрузка horses_or_humans...")
(horses_humans_train, horses_humans_test), hh_info = load_and_analyze_dataset('horses_or_humans')

# Анализ horses_or_humans
print(f"Информация о наборе данных: horses_or_humans")
print(f"Количество классов: {hh_info.features['label'].num_classes}")
print(f"Имена классов: {hh_info.features['label'].names}")

train_labels_count_hh = count_labels(horses_humans_train)
test_labels_count_hh = count_labels(horses_humans_test)

print("\nРаспределение классов в horses_or_humans (обучающая выборка):")
for i, count in enumerate(train_labels_count_hh):
    class_name = hh_info.features['label'].names[i]
    print(f"  {class_name}: {count} примеров ({count/sum(train_labels_count_hh)*100:.1f}%)")

print("\nРаспределение классов в horses_or_humans (тестовая выборка):")
for i, count in enumerate(test_labels_count_hh):
    class_name = hh_info.features['label'].names[i]
    print(f"  {class_name}: {count} примеров ({count/sum(test_labels_count_hh)*100:.1f}%)")

# Визуализация распределения для horses_or_humans
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.bar(hh_info.features['label'].names, train_labels_count_hh)
plt.title('Horses vs Humans - Обучающая выборка')
plt.ylabel('Количество примеров')
for i, v in enumerate(train_labels_count_hh):
    plt.text(i, v + 10, str(v), ha='center', va='bottom')

plt.subplot(1, 2, 2)
plt.bar(hh_info.features['label'].names, test_labels_count_hh)
plt.title('Horses vs Humans - Тестовая выборка')
plt.ylabel('Количество примеров')
for i, v in enumerate(test_labels_count_hh):
    plt.text(i, v + 5, str(v), ha='center', va='bottom')

plt.tight_layout()
plt.show()

# Загрузка cats_vs_dogs
print("\nЗагрузка cats_vs_dogs...")
(cats_dogs_train_full, cats_dogs_test_full), cd_info = load_and_analyze_dataset('cats_vs_dogs')

# Анализ cats_vs_dogs
print(f"Информация о наборе данных: cats_vs_dogs")
print(f"Количество классов: {cd_info.features['label'].num_classes}")
print(f"Имена классов: {cd_info.features['label'].names}")

train_labels_count_cd = count_labels(cats_dogs_train_full)
test_labels_count_cd = count_labels(cats_dogs_test_full)

print("\nРаспределение классов в cats_vs_dogs (обучающая выборка):")
for i, count in enumerate(train_labels_count_cd):
    class_name = cd_info.features['label'].names[i]
    print(f"  {class_name}: {count} примеров ({count/sum(train_labels_count_cd)*100:.1f}%)")

print("\nРаспределение классов в cats_vs_dogs (тестовая выборка):")
for i, count in enumerate(test_labels_count_cd):
    class_name = cd_info.features['label'].names[i]
    print(f"  {class_name}: {count} примеров ({count/sum(test_labels_count_cd)*100:.1f}%)")

# Визуализация распределения для cats_vs_dogs
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.bar(cd_info.features['label'].names, train_labels_count_cd)
plt.title('Cats vs Dogs - Обучающая выборка')
plt.ylabel('Количество примеров')
for i, v in enumerate(train_labels_count_cd):
    plt.text(i, v + 100, str(v), ha='center', va='bottom')

plt.subplot(1, 2, 2)
plt.bar(cd_info.features['label'].names, test_labels_count_cd)
plt.title('Cats vs Dogs - Тестовая выборка')
plt.ylabel('Количество примеров')
for i, v in enumerate(test_labels_count_cd):
    plt.text(i, v + 50, str(v), ha='center', va='bottom')

plt.tight_layout()
plt.show()

# Берем только часть данных cats_vs_dogs для ускорения обучения
print("\nОграничиваем размер cats_vs_dogs для ускорения обучения...")
cats_dogs_train = cats_dogs_train_full.take(5000)
cats_dogs_test = cats_dogs_test_full.take(1000)

print(f"Итоговые размеры datasets:")
print(f"horses_or_humans - train: {sum(train_labels_count_hh)}, test: {sum(test_labels_count_hh)}")
print(f"cats_vs_dogs - train: {5000}, test: {1000}")

"""Подготовка данных"""

print("\n=== Подготовка данных ===")

def prepare_dataset(dataset, target_size=(150, 150), batch_size=32, is_training=True):
    """Подготовка dataset для обучения"""
    def preprocess_image(image, label):
        image = tf.image.resize(image, target_size)
        image = tf.cast(image, tf.float32) / 255.0
        return image, label

    dataset = dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)

    if is_training:
        dataset = dataset.shuffle(1000)

    dataset = dataset.batch(batch_size)
    dataset = dataset.prefetch(tf.data.AUTOTUNE)

    return dataset

# Подготовка horses_or_humans
hh_train_prepared = prepare_dataset(horses_humans_train, target_size=(150, 150), is_training=True)
hh_test_prepared = prepare_dataset(horses_humans_test, target_size=(150, 150), is_training=False)

# Подготовка cats_vs_dogs
cd_train_prepared = prepare_dataset(cats_dogs_train, target_size=(150, 150), is_training=True)
cd_test_prepared = prepare_dataset(cats_dogs_test, target_size=(150, 150), is_training=False)

print("Данные подготовлены успешно")

"""Создание и обучение собственной сети"""

print("\n=== Создание и обучение собственной сети ===")

def create_custom_model(input_shape=(150, 150, 3), num_classes=2):
    """Создание собственной CNN модели"""
    model = Sequential([
        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
        MaxPooling2D(2, 2),

        Conv2D(64, (3, 3), activation='relu'),
        MaxPooling2D(2, 2),

        Conv2D(128, (3, 3), activation='relu'),
        MaxPooling2D(2, 2),

        Conv2D(128, (3, 3), activation='relu'),
        MaxPooling2D(2, 2),

        Flatten(),
        Dense(512, activation='relu'),
        Dropout(0.5),
        Dense(num_classes, activation='softmax')
    ])

    model.compile(
        optimizer=Adam(learning_rate=0.001),
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )

    return model

# Обучение на horses_or_humans
print("\n--- Обучение на horses_or_humans ---")
custom_model_hh = create_custom_model(num_classes=2)

history_hh = custom_model_hh.fit(
    hh_train_prepared,
    epochs=5,  # Уменьшено для скорости
    validation_data=hh_test_prepared,
    verbose=1
)

# Оценка модели
hh_test_loss, hh_test_accuracy = custom_model_hh.evaluate(hh_test_prepared)
print(f"Точность на horses_or_humans: {hh_test_accuracy:.4f}")

# Обучение на cats_vs_dogs
print("\n--- Обучение на cats_vs_dogs ---")
custom_model_cd = create_custom_model(num_classes=2)

history_cd = custom_model_cd.fit(
    cd_train_prepared,
    epochs=5,  # Уменьшено для скорости
    validation_data=cd_test_prepared,
    verbose=1
)

# Оценка модели
cd_test_loss, cd_test_accuracy = custom_model_cd.evaluate(cd_test_prepared)
print(f"Точность на cats_vs_dogs: {cd_test_accuracy:.4f}")

"""Дообучение предобученной сети Xception"""

print("\n=== Дообучение Xception ===")

def create_transfer_learning_model(base_model, num_classes=2):
    """Создание модели для трансферного обучения"""
    # Заморозка базовой модели
    base_model.trainable = False

    # Добавление новых слоев
    inputs = keras.Input(shape=(150, 150, 3))
    x = base_model(inputs, training=False)
    x = GlobalAveragePooling2D()(x)
    x = Dense(128, activation='relu')(x)
    x = Dropout(0.2)(x)
    outputs = Dense(num_classes, activation='softmax')(x)

    model = Model(inputs, outputs)

    model.compile(
        optimizer=Adam(learning_rate=0.001),
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )

    return model

def prepare_dataset_with_validation(dataset, target_size=(150, 150), batch_size=32, validation_split=0.2):
    """Подготовка dataset с разделением на train/validation"""
    def preprocess_image(image, label):
        image = tf.image.resize(image, target_size)
        image = tf.cast(image, tf.float32) / 255.0
        return image, label

    # Определяем общее количество элементов
    dataset_size = sum(1 for _ in dataset)
    train_size = int((1 - validation_split) * dataset_size)

    print(f"Размер dataset: {dataset_size}")
    print(f"Train size: {train_size}, Validation size: {dataset_size - train_size}")

    # Подготавливаем весь dataset
    dataset = dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)
    dataset = dataset.shuffle(1000)
    dataset = dataset.batch(batch_size)
    dataset = dataset.prefetch(tf.data.AUTOTUNE)

    # Разделяем на train и validation
    train_ds = dataset.take(train_size)
    val_ds = dataset.skip(train_size)

    return train_ds, val_ds

# Создание базовой модели Xception
print("Создание базовой модели Xception...")
base_xception = Xception(
    weights='imagenet',
    include_top=False,
    input_shape=(150, 150, 3)
)

print("Базовая модель Xception создана успешно!")

# Подготовка данных с validation split
print("\nПодготовка данных с разделением на train/validation...")

# Для horses_or_humans
hh_train_ds, hh_val_ds = prepare_dataset_with_validation(horses_humans_train, validation_split=0.2)
print(f"horses_or_humans - train: {sum(1 for _ in hh_train_ds)} батчей, val: {sum(1 for _ in hh_val_ds)} батчей")

# Для cats_vs_dogs
cd_train_ds, cd_val_ds = prepare_dataset_with_validation(cats_dogs_train, validation_split=0.2)
print(f"cats_vs_dogs - train: {sum(1 for _ in cd_train_ds)} батчей, val: {sum(1 for _ in cd_val_ds)} батчей")

# Дообучение на horses_or_humans
print("\n--- Дообучение на horses_or_humans ---")
tl_model_hh = create_transfer_learning_model(base_xception, num_classes=2)

print("Архитектура модели для horses_or_humans:")
tl_model_hh.summary()

history_tl_hh = tl_model_hh.fit(
    hh_train_ds,
    epochs=5,
    validation_data=hh_val_ds,
    verbose=1
)

# Оценка модели на настоящем тестовом наборе
print("\nОценка на тестовых данных horses_or_humans:")
tl_hh_test_loss, tl_hh_test_accuracy = tl_model_hh.evaluate(hh_test_prepared)
print(f"Точность после дообучения на horses_or_humans: {tl_hh_test_accuracy:.4f}")

# Дообучение на cats_vs_dogs
print("\n--- Дообучение на cats_vs_dogs ---")
tl_model_cd = create_transfer_learning_model(base_xception, num_classes=2)

print("Архитектура модели для cats_vs_dogs:")
tl_model_cd.summary()

history_tl_cd = tl_model_cd.fit(
    cd_train_ds,
    epochs=5,
    validation_data=cd_val_ds,
    verbose=1
)

# Оценка модели на настоящем тестовом наборе
print("\nОценка на тестовых данных cats_vs_dogs:")
tl_cd_test_loss, tl_cd_test_accuracy = tl_model_cd.evaluate(cd_test_prepared)
print(f"Точность после дообучения на cats_vs_dogs: {tl_cd_test_accuracy:.4f}")

# Визуализация прогресса обучения
print("\n--- Прогресс обучения ---")

def plot_training_progress(history, title):
    """Визуализация прогресса обучения"""
    plt.figure(figsize=(12, 4))

    # Проверяем, какие ключи есть в истории
    print(f"Доступные ключи в history: {list(history.history.keys())}")

    # График точности
    plt.subplot(1, 2, 1)
    if 'accuracy' in history.history:
        plt.plot(history.history['accuracy'], label='Training Accuracy', marker='o')

    # Проверяем разные возможные названия для validation accuracy
    val_acc_key = None
    for key in ['val_accuracy', 'val_acc', 'validation_accuracy']:
        if key in history.history:
            val_acc_key = key
            break

    if val_acc_key:
        plt.plot(history.history[val_acc_key], label='Validation Accuracy', marker='s')
    elif 'accuracy' in history.history:
        # Если нет validation accuracy, показываем только training
        plt.title(f'{title} - Training Accuracy')
    else:
        plt.text(0.5, 0.5, 'No accuracy data', ha='center', va='center', transform=plt.gca().transAxes)

    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.title(f'{title} - Accuracy')
    plt.legend()
    plt.grid(True)

    # График потерь
    plt.subplot(1, 2, 2)
    if 'loss' in history.history:
        plt.plot(history.history['loss'], label='Training Loss', marker='o')

    # Проверяем разные возможные названия для validation loss
    val_loss_key = None
    for key in ['val_loss', 'validation_loss']:
        if key in history.history:
            val_loss_key = key
            break

    if val_loss_key:
        plt.plot(history.history[val_loss_key], label='Validation Loss', marker='s')
    elif 'loss' in history.history:
        # Если нет validation loss, показываем только training
        plt.title(f'{title} - Training Loss')
    else:
        plt.text(0.5, 0.5, 'No loss data', ha='center', va='center', transform=plt.gca().transAxes)

    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title(f'{title} - Loss')
    plt.legend()
    plt.grid(True)

    plt.tight_layout()
    plt.show()

print("Прогресс обучения для horses_or_humans:")
plot_training_progress(history_tl_hh, "Xception - Horses vs Humans")

print("Прогресс обучения для cats_vs_dogs:")
plot_training_progress(history_tl_cd, "Xception - Cats vs Dogs")

# Сравнение результатов
print("\n=== Сравнение результатов ===")
print(f"{'Датасет':<20} {'Своя модель':<12} {'Xception (TL)':<12}")
print("-" * 50)

# Получаем точности из предыдущих пунктов
try:
    hh_custom_acc = hh_test_accuracy
except NameError:
    hh_custom_acc = 0.0

try:
    cd_custom_acc = cd_test_accuracy
except NameError:
    cd_custom_acc = 0.0

print(f"{'horses_or_humans':<20} {hh_custom_acc:<12.4f} {tl_hh_test_accuracy:<12.4f}")
print(f"{'cats_vs_dogs':<20} {cd_custom_acc:<12.4f} {tl_cd_test_accuracy:<12.4f}")

# Анализ улучшения
if hh_custom_acc > 0:
    improvement_hh = ((tl_hh_test_accuracy - hh_custom_acc) / hh_custom_acc) * 100
    print(f"\nУлучшение точности на horses_or_humans: {improvement_hh:+.2f}%")

if cd_custom_acc > 0:
    improvement_cd = ((tl_cd_test_accuracy - cd_custom_acc) / cd_custom_acc) * 100
    print(f"Улучшение точности на cats_vs_dogs: {improvement_cd:+.2f}%")

"""Оценка классификации с метриками"""

print("\n=== Оценка классификации ===")

def evaluate_model(model, test_dataset, class_names, dataset_name):
    """Полная оценка модели с метриками"""
    print(f"\n--- Оценка модели для {dataset_name} ---")

    # Получение предсказаний
    y_true = []
    y_pred = []
    y_pred_proba = []

    for images, labels in test_dataset:
        predictions = model.predict(images, verbose=0)
        y_true.extend(labels.numpy())
        y_pred.extend(np.argmax(predictions, axis=1))
        y_pred_proba.extend(predictions)

    y_true = np.array(y_true)
    y_pred = np.array(y_pred)
    y_pred_proba = np.array(y_pred_proba)

    # a. Confusion Matrix
    plt.figure(figsize=(15, 10))

    plt.subplot(2, 3, 1)
    cm = confusion_matrix(y_true, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=class_names, yticklabels=class_names)
    plt.title(f'Confusion Matrix\n{dataset_name}')
    plt.ylabel('Истинные метки')
    plt.xlabel('Предсказанные метки')

    # b. Метрики
    plt.subplot(2, 3, 2)
    report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)
    metrics_df = pd.DataFrame(report).transpose()

    # Визуализация метрик
    metrics_to_plot = ['precision', 'recall', 'f1-score']
    metrics_df[metrics_to_plot].iloc[:-3].plot(kind='bar', ax=plt.gca())
    plt.title('Метрики классификации')
    plt.xticks(rotation=45)
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.tight_layout()

    print("Classification Report:")
    print(classification_report(y_true, y_pred, target_names=class_names))

    # c. PR кривые для каждого класса
    plt.subplot(2, 3, 3)

    # Для бинарной классификации
    if len(class_names) == 2:
        y_scores = y_pred_proba[:, 1] if y_pred_proba.shape[1] > 1 else y_pred_proba[:, 0]

        precision, recall, _ = precision_recall_curve(y_true, y_scores)
        plt.plot(recall, precision, lw=2, label=f'PR Curve')

        # Добавляем точку для класса 0
        y_scores_class0 = 1 - y_scores
        precision0, recall0, _ = precision_recall_curve(1 - y_true, y_scores_class0)
        plt.plot(recall0, precision0, lw=2, label=f'Class {class_names[0]}', linestyle='--')
        plt.plot(recall, precision, lw=2, label=f'Class {class_names[1]}')

    else:
        # Для многоклассовой классификации
        y_true_bin = label_binarize(y_true, classes=range(len(class_names)))

        precision = dict()
        recall = dict()

        for i in range(len(class_names)):
            precision[i], recall[i], _ = precision_recall_curve(y_true_bin[:, i], y_pred_proba[:, i])
            plt.plot(recall[i], precision[i], lw=2, label=f'Class {class_names[i]}')

    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('PR кривая по классам')
    plt.legend()
    plt.grid(True)

    # d. PR кривая с микроусреднением
    plt.subplot(2, 3, 4)

    if len(class_names) == 2:
        # Для бинарной классификации используем обычную PR кривую
        precision, recall, _ = precision_recall_curve(y_true, y_scores)
        plt.plot(recall, precision, lw=2, color='red', label='PR Curve')
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('PR кривая (Бинарная классификация)')
        plt.legend()
        plt.grid(True)
    else:
        # Для многоклассовой - микроусреднение
        y_true_bin = label_binarize(y_true, classes=range(len(class_names)))
        precision_micro, recall_micro, _ = precision_recall_curve(
            y_true_bin.ravel(), y_pred_proba.ravel()
        )
        plt.plot(recall_micro, precision_micro, lw=2, color='red', label='Micro-average')
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('PR кривая (Micro-average)')
        plt.legend()
        plt.grid(True)

    # e. Сравнение точности
    plt.subplot(2, 3, 5)
    accuracy = accuracy_score(y_true, y_pred)

    # Создаем простую визуализацию точности
    metrics_comparison = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
    precision_val = report['weighted avg']['precision']
    recall_val = report['weighted avg']['recall']
    f1_val = report['weighted avg']['f1-score']

    values = [accuracy, precision_val, recall_val, f1_val]

    bars = plt.bar(metrics_comparison, values, color=['blue', 'green', 'orange', 'red'])
    plt.title('Метрики качества')
    plt.ylabel('Значение')
    plt.ylim(0, 1.1)

    # Добавляем значения на столбцы
    for bar, value in zip(bars, values):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,
                f'{value:.3f}', ha='center', va='bottom')

    plt.xticks(rotation=45)

    # f. Распределение вероятностей
    plt.subplot(2, 3, 6)
    if len(class_names) == 2:
        correct_mask = (y_pred == y_true)
        incorrect_mask = (y_pred != y_true)

        plt.hist(y_scores[correct_mask], bins=20, alpha=0.7, label='Правильные', color='green')
        plt.hist(y_scores[incorrect_mask], bins=20, alpha=0.7, label='Неправильные', color='red')
        plt.xlabel('Вероятность предсказания')
        plt.ylabel('Количество')
        plt.title('Распределение вероятностей')
        plt.legend()
    else:
        # Для многоклассовой - гистограмма уверенности предсказаний
        max_probs = np.max(y_pred_proba, axis=1)
        plt.hist(max_probs, bins=20, alpha=0.7, color='purple')
        plt.xlabel('Максимальная вероятность')
        plt.ylabel('Количество')
        plt.title('Уверенность предсказаний')

    plt.tight_layout()
    plt.show()

    return y_true, y_pred, y_pred_proba

# Оценка для horses_or_humans
print("\n--- Оценка для horses_or_humans ---")
y_true_hh, y_pred_hh, y_pred_proba_hh = evaluate_model(
    tl_model_hh,
    hh_test_prepared,
    hh_info.features['label'].names,
    'horses_or_humans'
)

# Оценка для cats_vs_dogs
print("\n--- Оценка для cats_vs_dogs ---")
y_true_cd, y_pred_cd, y_pred_proba_cd = evaluate_model(
    tl_model_cd,
    cd_test_prepared,
    cd_info.features['label'].names,
    'cats_vs_dogs'
)

# Дополнительная визуализация прогресса обучения
print("\n=== Прогресс обучения ===")

def plot_comparison(history_custom, history_tl, title):
    """Сравнение обучения собственной модели и трансферного обучения"""
    plt.figure(figsize=(15, 5))

    plt.subplot(1, 2, 1)
    plt.plot(history_custom.history['accuracy'], label='Custom Model Train')
    if 'val_accuracy' in history_custom.history:
        plt.plot(history_custom.history['val_accuracy'], label='Custom Model Val')
    plt.plot(history_tl.history['accuracy'], label='Transfer Learning Train')
    if 'val_accuracy' in history_tl.history:
        plt.plot(history_tl.history['val_accuracy'], label='Transfer Learning Val')
    plt.title(f'{title} - Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid(True)

    plt.subplot(1, 2, 2)
    plt.plot(history_custom.history['loss'], label='Custom Model Train')
    if 'val_loss' in history_custom.history:
        plt.plot(history_custom.history['val_loss'], label='Custom Model Val')
    plt.plot(history_tl.history['loss'], label='Transfer Learning Train')
    if 'val_loss' in history_tl.history:
        plt.plot(history_tl.history['val_loss'], label='Transfer Learning Val')
    plt.title(f'{title} - Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)

    plt.tight_layout()
    plt.show()

print("Сравнение моделей для horses_or_humans:")
plot_comparison(history_hh, history_tl_hh, "Horses vs Humans")

print("Сравнение моделей для cats_vs_dogs:")
plot_comparison(history_cd, history_tl_cd, "Cats vs Dogs")

"""Сводка результатов"""

